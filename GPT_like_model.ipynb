{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "8itFxqwTuyJi",
    "outputId": "cd8b64e0-e009-4f70-cd57-1ca5a98c40b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.36.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.2.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2025.11.12)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Tcpy-NwDtuo"
   },
   "source": [
    "# **GPT-Like architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "o2qQyicmu1EF"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "# -----------------------------------------\n",
    "# Self Attention (1 head)\n",
    "# -----------------------------------------\n",
    "class Selfattention(nn.Module):\n",
    "    def __init__(self, d_model, head_dim):\n",
    "        super().__init__()\n",
    "        self.head_dim = head_dim\n",
    "\n",
    "        self.q = nn.Linear(d_model, head_dim, bias=False)\n",
    "        self.k = nn.Linear(d_model, head_dim, bias=False)\n",
    "        self.v = nn.Linear(d_model, head_dim, bias=False)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        # x: (B,T,d_model)\n",
    "        q = self.q(x)   # (B,T,head_dim)\n",
    "        k = self.k(x)   # (B,T,head_dim)\n",
    "        v = self.v(x)   # (B,T,head_dim)\n",
    "\n",
    "        # attention scores\n",
    "        scores = q @ k.transpose(-2, -1) / math.sqrt(self.head_dim)  # (B,T,T)\n",
    "\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, float('-inf'))\n",
    "\n",
    "        attWeights = torch.softmax(scores, dim=-1)   # (B,T,T)\n",
    "        output = attWeights @ v                      # (B,T,head_dim)\n",
    "        return output\n",
    "\n",
    "\n",
    "# -----------------------------------------\n",
    "# Multi Heads\n",
    "# -----------------------------------------\n",
    "class Multiheads(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super().__init__()\n",
    "\n",
    "        assert d_model % num_heads == 0\n",
    "        head_dim = d_model // num_heads\n",
    "\n",
    "        self.heads = nn.ModuleList([\n",
    "            Selfattention(d_model, head_dim) for _ in range(num_heads)\n",
    "        ])\n",
    "        self.out = nn.Linear(num_heads * head_dim, d_model)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        # compute each head\n",
    "        outs = [h(x, mask) for h in self.heads]  # list of (B,T,head_dim)\n",
    "        out = torch.cat(outs, dim=-1)            # (B,T,d_model)\n",
    "        out = self.out(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "# -----------------------------------------\n",
    "# Feed Forward MLP\n",
    "# -----------------------------------------\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, d_model, expansion=4):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(d_model, expansion * d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(expansion * d_model, d_model),\n",
    "            nn.Dropout(0.1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "# -----------------------------------------\n",
    "# Decoder Block\n",
    "# -----------------------------------------\n",
    "class Decoderblock(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super().__init__()\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.att = Multiheads(d_model, num_heads)\n",
    "        self.ffn = MLP(d_model)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        x1 = x + self.att(self.norm1(x), mask)\n",
    "        x2 = x1 + self.ffn(self.norm2(x1))\n",
    "        return x2\n",
    "\n",
    "\n",
    "# -----------------------------------------\n",
    "# Decoder\n",
    "# -----------------------------------------\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, dict_size, d_model, num_heads, num_layers, seq_length):\n",
    "        super().__init__()\n",
    "\n",
    "        self.emb = nn.Embedding(dict_size, d_model)\n",
    "        self.pos = nn.Embedding(seq_length, d_model)\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "\n",
    "        self.blocks = nn.ModuleList(\n",
    "            [Decoderblock(d_model, num_heads) for _ in range(num_layers)]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T = x.shape\n",
    "\n",
    "        x = self.emb(x) + self.pos(torch.arange(T, device=x.device))\n",
    "\n",
    "        # causal mask shape: (1,1,T,T)\n",
    "        mask = torch.tril(torch.ones(T, T, device=x.device)).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "        for block in self.blocks:\n",
    "            x = block(x, mask)\n",
    "\n",
    "        return self.norm(x)\n",
    "\n",
    "\n",
    "# -----------------------------------------\n",
    "# Causal LM\n",
    "# -----------------------------------------\n",
    "class CausalLm(nn.Module):\n",
    "    def __init__(self, d_model, dict_size, num_heads, num_layers, seq_length):\n",
    "        super().__init__()\n",
    "        self.lm_head = nn.Linear(d_model, dict_size)\n",
    "        self.Decoder = Decoder(dict_size, d_model, num_heads, num_layers, seq_length)\n",
    "\n",
    "    def forward(self, x, outputs=None):\n",
    "        x = self.Decoder(x)\n",
    "        logits = self.lm_head(x)\n",
    "        loss = None\n",
    "\n",
    "        if outputs is not None:\n",
    "            # Before unpacking, ensure logits has the expected 3 dimensions.\n",
    "            # An extra dimension of size 1 might have been introduced unexpectedly.\n",
    "            # logits = logits.squeeze()\n",
    "            if logits.dim() == 4:  # If shape is (1, B, T, V) or similar\n",
    "               logits = logits.squeeze(0)\n",
    "\n",
    "            # flatten for CE\n",
    "            B, T, V = logits.shape\n",
    "            logits_flat = logits.reshape(B * T, V)\n",
    "            outputs_flat = outputs.reshape(B * T)\n",
    "            loss = F.cross_entropy(logits_flat, outputs_flat)\n",
    "\n",
    "        return logits, loss\n",
    "    def generate(self, x, max_len=576, temperature=1.0, top_k=None):\n",
    "        \"\"\"\n",
    "        Generate a sequence given a starting input tensor `x`.\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        B, T = x.shape\n",
    "        generated = x  # Initialize generated sequence with the input\n",
    "\n",
    "        # Set the model to evaluation mode\n",
    "        self.eval()\n",
    "\n",
    "        print('hi')\n",
    "\n",
    "        # Generate tokens one by one\n",
    "        for i in range(max_len):\n",
    "            logits, _ = self.forward(generated)\n",
    "            # print('logits shape:', logits.shape)  # Debug print\n",
    "            while logits.dim() > 3:\n",
    "                logits = logits.squeeze(1)  # Remove dimension at index 1\n",
    "            logits = logits[:, -1, :]  # Get logits for the last token (T-1)\n",
    "            # print('logits after slicing:', logits.shape)  # Debug print\n",
    "\n",
    "            # Apply temperature scaling\n",
    "            logits = logits / temperature\n",
    "\n",
    "            if top_k is not None:\n",
    "                # Apply top_k filtering\n",
    "                values, indices = torch.topk(logits, top_k)\n",
    "                logits = torch.full_like(logits, float('-inf'))\n",
    "                logits.scatter_(-1, indices, values)\n",
    "\n",
    "            # Sample from the logits (softmax for probabilities)\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            # print(f'Step {i}: probs shape:', probs.shape)\n",
    "\n",
    "            next_token = torch.multinomial(probs, 1)\n",
    "            # print(f'Step {i}: next_token shape:', next_token.shape)\n",
    "            # print(f'Step {i}: generated shape before cat:', generated.shape)\n",
    "\n",
    "            # Append the sampled token to the generated sequence\n",
    "            generated = torch.cat([generated, next_token], dim=1)\n",
    "            # print(f'Step {i}: generated shape after cat:', generated.shape)\n",
    "\n",
    "        return generated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "bEyqDWAUBfvn"
   },
   "outputs": [],
   "source": [
    "# Creating my GPT-like model\n",
    "# i'm making sure d_model % num_heads = 0\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = CausalLm(\n",
    "    d_model=256,\n",
    "    dict_size=30000,\n",
    "    num_heads=4,\n",
    "    num_layers=3,\n",
    "    seq_length=576\n",
    ")\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2cJj3dHrEQIo"
   },
   "source": [
    "# **Tokenizing My Training Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "caa5b9137a0342888a84f7cca75a6534",
      "beaffc78617e48d4ae5ce9225f82190d",
      "3d9789b82362402894fb6a745e6e5d0a",
      "c83a852fe6ba44a4929aef1cd93f0750",
      "f82b1cd0965b4282851e6e71fce4cb02",
      "f19a33ce1c384f0a8a0e9b0d8caf8eaa",
      "a8700779c1524f4e9c9ad2fcd0f41039",
      "170bd34f61e84366a754b7d354774f01",
      "37599005b58644c9b70f841a50ddc52e",
      "39189f058dd6435bb5f2cf008357cd74",
      "da5c948f271749658bda074fa91848ae",
      "b68a05287f2b4b8e9484cfcb4d3b82ef",
      "cd34f0cfc6ed4339a005a52af4d025b5",
      "3b49a477d6eb4fe29f73215de414455d",
      "75e735a2c4d741c6812a1966a8e40aae",
      "09b8585cace348939b03b5a49d4d8a5e",
      "11478afcc1894de2b360902841db3e84",
      "4cf3543a26894e818ffa78490983177a",
      "ea82f9618978458491b22ece3caa037e",
      "9dd3030ec171412487b8a7f765c72450",
      "5973857bdc67487e9e3ce8be29aa52f7",
      "1d6f1fa909ce4902863eaa66bd283a77",
      "b1fefc6c887d479eace03f74c8e4db07",
      "ddc62b26b81b4f799120c28b072f8f2b",
      "207fba31e86f400c9f5a8f55ff29bff8",
      "633f5e34cf2342fe8adefabb95e9bb28",
      "659804590d674d26852f17d2e3843079",
      "77457b7b55ec4a469f1a68086f689333",
      "dffa6483ef024dbf888cfd354119d2f6",
      "9a13a1e7154546d8ae5c181d84fda1b3",
      "c3809602d2c54631a3b3e72b21d81577",
      "3692781dc139487f9fd2a321bdd36bf4",
      "d7c4cf1a19b644228b0e743529ab6b6e",
      "c79395f675b8465ab746a4e724f21731",
      "606347ae2f8643388c175c40c03f8b4a",
      "140b996211864f1f91f54a33c9daeedb",
      "149849e63beb4ef6bcbc4ff8716ccbc3",
      "2659659415c94309a3f9f98e21cdf480",
      "c4c0a59935c646e1a4b3df79c9eaba76",
      "7d52c1e586ff4e368ccfabcce7d5a4c5",
      "bcda7f02ab584c508aa910d9392e69a3",
      "c3a3815f6b16480bafd1e8d84926c37c",
      "50c9ff1f911e4adba1ca42f79dddd461",
      "3d5868c3573c4073815fddffc87b28c9",
      "735ca48204df4db5a9e11aabbcedda4e",
      "1240d5f692294a88aa7f48b862f9ffae",
      "90036403f63f41ccab2c15d123555079",
      "4cbf29d6116c437bbfcdfedc7cfb26fa",
      "e98ee171b29d4fc2a19a748dd8e1d1aa",
      "90e39b4cdc2a42ccaf7e129287e2d755",
      "fded369feb2642c0b44c55d764533d29",
      "6af344673a45477dbac052adc0557313",
      "f875bb9f88f54bd6b153c39e61481f67",
      "e492e0cf67cf4e94b9aff4ad33426aaf",
      "4feb26ed4cb645d6822bba40f44e57c7",
      "9210e373a12145aea3c0c3c25a8f31be",
      "8fc030137e914cdfa2e97f27483c3377",
      "fdac6ba37dc44fe5a56161ee19f02a9c",
      "b1c9c895fca744ed80837ff23d843806",
      "cc4d5fcc433e400b995fdf7bd240a8fd",
      "bec15ce7d77e40e7914c9e6761a719ff",
      "3bc374c134b246b6a246921c4acc8411",
      "f232be57a98049f9bb9363112dfb0ed2",
      "1c8f72c5c7c6443499b325ab47729c6e",
      "b923dd78e65a4af0b9aa98df66ec95b6",
      "f881c26730474ce6afd4306251f3d425",
      "07f0cbd40b294332b52e6245c94bf8ea",
      "6d8b794774104a23b430a96bf06c8dc2",
      "ba95bc1467ba4c10bf237e2c019aa7d9",
      "c67118b83c594a61bc6782621a560141",
      "5bd87533fe8b463098bc17a82c2c77d3",
      "6ff4385ae3514bce9c3570b36211d157",
      "a2873401b9704056812fcf36141e4b01",
      "d2b8a309a9f2469b9e8e8442e22b09ec",
      "9fd42d9a43d3401fb16ffbea8ddcb9b1",
      "c299b2ffab7d40e1a8fe394667b7a429",
      "25d13d7933504db3b48db81843284ec8",
      "856b9cdd36804e5685dec3a068b1c197",
      "835150c21fcc43bf8116e9bb003b1b92",
      "7946191ac5f040af9eaf463e64563be0",
      "f0b3e514fe5f49cebed04c4c6b8359df",
      "0f8004de63e74354a5eeabc02c623b31",
      "2e91567802d847308c45f3341305dfdd",
      "7d4e1b07086745aaae8d2f98f30be6ce",
      "2f78bec080754af4bf9fbf6add843d38",
      "1d59bed8a0594f3781f010c63b22e63b",
      "f21bd281fdaf4a8cbbba5ee093fddd2d",
      "d106d6db09234b23b98d9a1cdda571d9",
      "eb94fc37ae734dfe8886d291a9540a67",
      "128608dc4fcb4cafbaf656bd6c59f372",
      "fc504ff9174c4b99ae97f9c97fe9ed1f",
      "a1828af93cb24f8aaff9f4cc85ee5192",
      "5b925d085e5f4d93ba7d7e7831cdf9d3",
      "32c5d9e1c8134619a11ebac4af47a595",
      "fd9f22f7e4f4433fa1835d64314d87aa",
      "a845e29e6e3c4a0e99dcd63f0a131c42",
      "77e9b033cc234a1eb82329cd863b25b7",
      "2d685fa450ec4f1e82c11c76e69744f7",
      "bfd7b9131a9b41f895e27ced68a88285",
      "f7d185b9961b47e1b2876aad7d637913",
      "c5de4a5d3dc141abbda20ff1506922d9",
      "5b7a45dfab31430cb44e3aadbe6592e5",
      "a4520f8abf2945fc8735831928d55c52",
      "42f041d416e041a59f222eed008fcfff",
      "bfa084d2dd5a4a79a38a89db4a7d8a67",
      "90b53f6826874fe4b4fd45ba1490dd30",
      "0a1a8840d466466a9bf3e63a4e2765f1",
      "d0c3da77776143dd855aa54f1743d13b",
      "9bb0a90cc2d3450d81eb7da775ac146e",
      "aa0f8bd5eeb2470eb6c9643fe63b8ae5",
      "4549e39db2834769b79d780273aa89f7",
      "7f070db84f4a4ca885b38e21c354f040",
      "952d70d7ac0f4ede9e0a60f0ddb374bf",
      "66d047436fd64fe0a9e6669f740a46f6",
      "fb3084e98530427eb949eefb72cc69c1",
      "bcb2397419b84abd93afe36b01b4d8ec",
      "6e52d38968f74264ad9c42d1298dafbd",
      "d68e1fa0a8c44c458f544201275ee9b5",
      "72725159c75948b98530e7c8395b6f45",
      "04ffbf7285c14e218d9286bcd37fb4e7",
      "2fc1c3c81f0a454f89f29377cac64cf9",
      "06842af40312417ca890a20536ae16a7",
      "ce80a987f0c24cc9887f9036171b44e3",
      "68f4fd69526a4475b0ca26371d17659f",
      "7d38ba7975eb470092f9bd809dfa70a2",
      "5a6f2d75226e431e8f6d51b498be6186",
      "7333cb596c1c43d78970d49f224098c2",
      "88271226f3a34891b7b3e82cf97e0986",
      "22cb1f8361ed465098dffdc84e9e6272",
      "d0f9602d618d42d8b00f4fceef33257a",
      "cbe4aa68e8154e91a00a36681ddc055c",
      "54f082fce1f74a379904b21f1b33c8df",
      "067c11a0f92e4b0f99db5942f998c2ef",
      "5f68bdcfbdb744659d762e436b721182",
      "089af46c7c474652b095ba6e3529d9cb",
      "b605152a6a204a14b37831658328a56e",
      "3177abda96334943b34a5a25e56ccfb5",
      "a9810bc2e2044ad09f127fbfee99eb70",
      "d26ddb8231744559a48bd6fd7238081d",
      "e61e988a14c84088995b62023ad2f528",
      "1a5ca1aad1c0464ebec0d82eb0f43e97",
      "061b65098c9f46fdb5b67e99d2878a5b",
      "484c59b8693d46a59110fb15780678b8",
      "23f2a01d8e904dc0b1df8e81857c7ac5",
      "a192d0dc079f4f4cb95b18ee54a94a82",
      "748820011119421aada2a5671ca845f6",
      "9ff20c95d5b743a7970751f6ee4e6034",
      "fbad1603aff34b6d8732fa60f5a4b5e3",
      "01c62db669f845e4983682412bf1b06a",
      "d9447d17b9f944249735c5befcc71bf2",
      "7265fca8ea5140bca81a1dcc39a564b5",
      "0c072c41e32d41c382f70ba4c9759771",
      "24388d6df5a04df2b43febfba013d2e6",
      "2445fd8c0bf24f6f86336e572ab7242e",
      "dd25eee0d27b4e19bbae193732206c6b",
      "256da971587649eda1d3a042d7432ab5",
      "6988c818570b4385b09f70b9d85c394c",
      "920b3c343db24246b9584d1aabfd3c52",
      "ee8460afc0ec4c43b170d5650fd8df30",
      "63fbd2a63fe547fd84485d65532359c2",
      "6e7b3f6387a84ebb88f25733e9be16a7",
      "70496aab1f2b46dda56fbddd237033c3",
      "0b8286de71fd42a78f6b7f918b16d8b8",
      "c8706d2894514347bfd0a01166e6704b",
      "e3782f6e3b85413ea9e8c0ad6546f5ce",
      "57e535056fb546f9ac5a61767da1e8b3",
      "87a314fd552f45678079bd16e47eaed7",
      "b91b0dfb55044c50b9bec99f84624f32",
      "3e665ed5841749eeafc6be1c4e0c1d09",
      "249feecd5c394468bc707cd6c78815df",
      "ea936e6447874dd0b7ac88a4a7e7f08c",
      "823762b9dd3043a28b4fba4a45148082",
      "44b382988f1c4259b431e2ca032b412b",
      "b319978a4bbb40879bfdd3aedb2396e6",
      "84e3facfbb05455ea07ba7967c11f194",
      "184ccd2e5095451e9336cb2e1ac4447f",
      "e622719e0eeb4b43a17c2b8e4b03dd8b",
      "57b2586245cc4bb2a2ff65187e60e745",
      "3ad74e4332454079b150fd033ad0628f",
      "c2331c4e82b34f8e97cd8736b3010657",
      "9c761c5032b6489283a1ebf7c95068e0",
      "1a1907225d8e4dc48d7d370b6d7738c9",
      "48ac81a4b4d545b88455fe66a0089ef7",
      "351ec3130b694c379cdc820df0435337",
      "b1f88e9a9f0f4050bb41db796b4e5bdc",
      "bd7e4c77767248bc8a7327688c88f1f6",
      "862374f3ed4f4b2aa2f3085bc8bb5473",
      "c9b1392a5b3e487798b3e3f5f2825e6f",
      "d3937842b95b415a9735a598f2148f6f",
      "9ca4ed2bea9c41d59353d6937378da43",
      "062224af706c4936846d15967412b89e",
      "b12cc729fc6f48cb82df2701279b698f",
      "73d3e578775349269f522a1a23555cfb",
      "2bac2657dfa94c1d86bbe485d1391cc9",
      "2cc97e19de804c329e7930f7f8016a3d",
      "e839340740ef40bea9ed3ed0b0427e26",
      "d56e7786dc1f4a30a670a36d4b2c5521",
      "bb9a867a5c064be8bd1836d2d42e2c70",
      "6225dfc0a3bb4d0ba53e213c4ae73904",
      "9e073256b62e421e808a1acb34b8dd48",
      "f4c104d8fa7f4852b5a19134f840d884",
      "5555cf76ed81456f9f50779d1646279b",
      "42b7f85577ac4b0d8f51c6cf593ef63d",
      "486415086876499ebf652568de059f3a",
      "01bf829665a747d78d7316720fe440b0",
      "7460bad27f9e4f97a3d71769bdbe85b5",
      "fb0fc2bd0a1f49ae86007b8445777c20",
      "524178d5a45c43cc8db7fdd3ddf205dd",
      "5bfa5819a7274db3883be1476c7868c1",
      "4c3a6e0262c9491589ce5aff7257c790",
      "fb5ce85287cb4dc08620ef84588f4771",
      "5189cfbc6d49404fbb3e30722be0a945",
      "53960c01677b48e599ed48ded3188c0c",
      "d153925c777f48839aa7300ed34318b1",
      "1508ed13d2944afba10103177f4fc620",
      "441cb22f33b54d45aad8d184326a9433",
      "84fad5a33a724c7ba0cc540fffb27665",
      "acb58a339b79422a82ea718cfd1cd969",
      "af4267cd884542608fe084f8f3636ff5",
      "360a808db4fa456395118ee9085afda2",
      "1ab114565d294488b57e067e9776e37b",
      "ee2e497131d248d481634f6034895565",
      "7e51490487ca470aafe101d6ff3cfcfd",
      "c8780258c4f047ffac9dce24f9b87830",
      "9cf15a84607147d8a5d18d3d58098bff",
      "41ede946235f4533b270ca079a2d92ca",
      "bc9b2cfc6feb4cc2a56b18ba5f7590f3",
      "400338af7cc942e3b8082aad3397845f",
      "1421ccfe2e9c45e5b548e75089b8672a",
      "acabedac3b554c53b6a0edee7268af03",
      "2f52aa716d8e42fc853a43a04363d284",
      "a02f3e62bdde497182aac93efe0708e2",
      "613fb119318742f5a897b3a0aa598c35",
      "42ac43c7e76e450da8d7c1c079cc05a0",
      "90e8d83300c742ae930c60cdce3300ba",
      "2041d6b018ef4a61956ebc724e532be7",
      "d6f5ae025b964662bf1aef2a41e500a1",
      "e33eb212850c4e65834ce9d5b7ba3026",
      "345bd0b2fdc54431883ab468792c9f33",
      "0cff8cc633f243ea8e5ed2b72a6678b8",
      "069a352a316147cab60c3176a6092311",
      "f4774b5919fd4ae3b699981b37a00463",
      "75d4436a90144b5bb89c8a7e315308dc",
      "f8cf92a42ff14eb48b11d6a3bb876c5d",
      "eeb09e81b4b045dab89b994a72fc51b7",
      "0e6984859c8248bab30618c2b1819dd7",
      "728cd4f687134db48290e2079a782f33",
      "e6969220ad534c74acde25e18a66cd93",
      "417ca6bbcaaf4d59bd9f395173565808",
      "9dde5281df804eaba289bbfc6adb9d74",
      "b70712b668cd4753bd463862cef61968",
      "5357e2decc7b42d5853d6bbde8b5d268",
      "a2021c25096547ed99a4e783668c6a05",
      "8051e4408b2149f8b472c9ba6767ee21",
      "927696118ff946b3892f6efd330aa15f",
      "2a01788bab424b1a8f20c6d1cb86585b",
      "f2e9f448222a47abb241fe41003d435e",
      "4e4df76372fc409aa9e87473fa417dc4",
      "d139748d02b745e6a6231d03c7b7ea11",
      "2f0c5fd61a6147c48eba67a128bd2254",
      "934d5748eebb40c88111a324c101a5dd",
      "d7488440003c40a38f9e4f5ea001dc8a",
      "7868460d231347519eaec24bca8fd9b2",
      "0ba18d2cfded442ca0c7ddf51b92ad86",
      "1d0e2c7c636a47abbd4a9d819098090d",
      "50b6590ea5e24bb3935cb750e127adfc",
      "f7c0f634ced94c918cf23286aef58d7f",
      "6d0c7645d2a04666972c329295d6af93",
      "3576423ad2ef43f5980d50e53fd08572",
      "35dc06b3ad194f43bc452e681726c170",
      "09901c32ef764c66a609ceb3dd51dd93",
      "81bdbde94b434a78833fad7ec1473d85",
      "25baf0828921489bb4fbad7d4db3750f",
      "b36b0eff69044da1a51ed9427340dd89",
      "a62a2b3cab4149d69266fc40fd1303ee",
      "7edb761e5f1544cc968218e2a6b25cf0",
      "382782c3aee246c9837e33a30b15d3dc",
      "8e92b4b221a4431ca28984fe62809f27",
      "2dc76969b90f4f0c87f455d2b6ee90f3",
      "7a99674e0191493da6c6bba14b8966d3",
      "faf98cfac1a94edebb257a401a446d73",
      "793bf839566d492db41197be61a13927",
      "838a01f2980b4145b6d9a85d5f323502",
      "2dbe20103a53470d958f92dd49328887",
      "e0cd70e31cb3404cba212ef836ec48ff",
      "a768d348e4f647e784116107cfc09156",
      "ff1a35c4abe94419b8cee294cdd557bd",
      "8c113f4cbb30435aa5836745098ae8cb",
      "af52487ffe5345e2824349ad6c2ef14f",
      "ee1a28e324bf4d5a96dcc577cd722283",
      "3cf6974ce4e94da8b6bad8f689cc7ea3",
      "096e8a0df7424641b68df3e5462e9028",
      "33f37c64d3824ffbb93a924081b792e1",
      "e002a868f7f74bf2904dbd754e46f769",
      "5713f2e4004543e9a78b4ad4373f00b4",
      "99a144289b784321b28fe44503c5fb6d",
      "71fcafd1df014a59a0b3679c9c466ebe",
      "f9306ef94e3c4ce3b36a5ee885c30919",
      "daee13042f5e419b841675c5bb75fb88",
      "46053c8d12c34ffeaf9e1e3e91587071",
      "ff28c6f6e2fe45438d662afbd0a300e6",
      "67db9d1bb5a54f238806f00e326288b5",
      "7a549660374c4a13b6d2445c1afc7778",
      "fcb9480529414ea8aa24ad2dbd0c751c",
      "dac50640432e4afb8480c2161ada3be6",
      "b1405b5798bc4bd3a9e3ddfc1ad5af2c",
      "f720c045b6fe4ce39a8f66f0387f0ebe",
      "302651d720014b28aac216d6ec4589bc",
      "58d8119bb1ab49d0ac2e11aaec9e85b9",
      "5fc9498980b140afa95e9b7929ce9c8b",
      "fd1c4c6d04c247519494f8853c21b33f",
      "0e1a69db6fc242d2a940523b9db05df8",
      "996c0cf2998c48ce9cdac69a90ae5e82",
      "ee63d1fcf5074a43856c0bd08d63dbc1",
      "76512313697b41bc905173fb24be130f",
      "b7e33e49018a460085c758c4bf932e5a",
      "ba836405c52547d4ba2c24c8ef887db2",
      "f71743856b924feaaf26d1de8264b827",
      "b3c52e9427694687b415a08fb0e8a9fd",
      "72110ce3dc1d45f886646433d925ca9b",
      "281929e4afd040fd86cec255b46e9501",
      "8fd13a42e95b4a449959c1f90f380887",
      "f777e391371849a9b047fe10588ac31f",
      "5db083f32ad74afdbf3cc993e9bc25a1",
      "b6a7c36ef05a4f92b9e35e0f88ee71f7",
      "7061a58305164022888a16ab02dfe98d",
      "43f9acddf7f3453bb25898efa635f912",
      "e7067458448248f09cf8a10ddae32376",
      "c7bfdfee7b4c462492a9e421e785b72b",
      "738114ad24b04a70bd558b24674ebcaa",
      "5de23ac23ba04e21bd8174193601044d",
      "2d98d239e6a4455d8c10df94e99961c3",
      "fc4c7986e3fc40be8d575aef194e66ca",
      "2a2cdde1c72a446591ea7d329bfe8411",
      "da7bee89e0b544ff96c669efd2b3d476",
      "513b54489f574dd6ac7a86f18bbf3447",
      "e5b0c7aedcbb4e7e9759dab0c99a55c2",
      "da06d47e90684a30a19468dfae8a917b",
      "72623a034f234dc6a2e1521303e96aeb",
      "f41589cdcc0e4332b6cbeee112da03ab",
      "143819a5b87d49f88cf9e642b5681b9e",
      "eff03a810bf94026a0d968bd6ce44eea",
      "bb39a1e886524b62aeeacb9a7c33480b",
      "735001e382a049a1a0663138e7d94cdc",
      "852d463d9e0f459e92df981b34040fbd",
      "f4ef15d314654839a901f1a5175c5e3a",
      "5ea305f2fcb14658b98255740e86639e",
      "014c7833cc4644839e5064254e2a6326",
      "a3196a3aa43d4a80a97f7d68c056ef73",
      "db8472e1cca04509a4a75bbad687c138",
      "724de2e01f8141f7bf2688e2c0717a0c",
      "047711860eda4c61a0eda787efc5c8ca",
      "6ae4dae041f04e4e88d51ba28897f8a4",
      "a1a216b02cde43218f9bc446ef8f68d9",
      "fb44aaad46a74714a655e5037f8c3338",
      "1f760445d8794d658d88f3558e5facaa",
      "8b2a1d4d8eff4c8d8206d43c0ab1b7e8",
      "1be8c1ec20e44ffbafb64a2170b4e96e",
      "2317a82c1e054234b8d48b4010866a44",
      "aab7a6d87b76441fa30cde4f9ee8cc1a",
      "539eb73a9aa64b1db1bb32dd2ad5c693",
      "cb389e40a4714f5aa92dfcd0686c2e19",
      "68b54ffcaa604a3c864201acc6e7f662",
      "5fe3f09f8f5e405a84962f4a390347cf",
      "f5ce6146146d4f66bc4bed286b38d4d8",
      "b466d614542a4e1e88d387b2fab04c1f",
      "f3ad5518a33a434f8b3c92f6ce56e909",
      "5dc6a3814e3b4289b4bd22f92cf19dd5",
      "d66fa1458ecf451a8169e899f126484c",
      "a70e67d531d1485ba51870c6cda90602",
      "1a36a213df044f6a8564275f2be72205",
      "f0a04b2574a7455b9d887ed8378f1162",
      "cab02bb68a44482f81d5758408704a54",
      "4450f256108348b28d595944ec1588f1",
      "8a862613e9e24e519cb8223688d9a72c",
      "d585e58462bd48dfb6a7110a786621de",
      "a8f6b280d32d4e3c97fad2e8219dd0c6",
      "786051e4a5f04a378f2760646db932a5",
      "e0b3fb516e21469a8c4320634ec7b562",
      "a263928f6ce841c08af8f1093c55f8fc",
      "08df0ff597664972909f8d3d2bcd8e95",
      "b4593ea234d44e54ac898a9562d5077e",
      "076bdd1791a1429395908a4641d10bac",
      "aa67cb9fc7f84896b3115c2b61f19a1e",
      "3d15a90af96440ecb2ae4ba29029ae8d",
      "0b22b72d0ac449309602b316f10716a5",
      "43538835f7b84d42bd8b5271f5278cf8",
      "81ff6797180d4550be91573d5e2ccc9f",
      "4f3093da41b04cb98a1d8e5ed8d79635",
      "92780018bade48fc9f1aff6c4d6f6df7",
      "3ddd5f3a374c48ff921341b9c74d63cb",
      "5540e7b87362428ba481ae868ff0ffa0",
      "d2bfa52cdfaf4c48ab35d15b2dacaa3c",
      "2de0f9e981434e4fb9f189af66ed8a88",
      "0378b8b5bff84f32bb52a71e8bb4887f",
      "1ce5da69c2ca4739b3ad697aef41e648",
      "50c9d8945edd4e29b79bdb53934257ba",
      "a3eb0bfe59b64499ae33ae632ef1b747",
      "14d6760bd19e40c6a489444a0bc9fb61",
      "822fff35108a47a0904ee9e06a14a518",
      "709535740fcd4e8fb24b89149631472f",
      "c06b7ea10c4c4a668f89e380584a77db",
      "47a2cc37dba748f4af208587dbd4cdbd",
      "8fbccc2c78ab4a36b47dc68fb37a3663",
      "ca1c9c1782ca4d54b93b40e87f504774",
      "afb0396572f44f3d887da8ad48686f83",
      "86049afca72247fa84f9d9ae8cd085d1",
      "4fc2a7cbd2a748faa6d17fa336b002bb",
      "646feefd7f8f4158b95dcfe83e168dcb",
      "df8b7d5fe4e24c548f429f091556c234",
      "c782c032829f45bf91df75418347933c",
      "dbc806f3b69e4b5bbe8d6ea1a70d4add",
      "8774c6ea80aa4094b81d9e644c9c69f9",
      "e735b8b81ac9455b8fb9d4eb379fa262",
      "e1fdf2961e864881830bf6476179def7",
      "dfca96fc767d42f9bd65d2f5c71dcaa4",
      "79d063cdf9d146a3b28602ee81eb29de",
      "4c9612aedbe04f089f294784004984b4",
      "30c78e71895a453c8f262b4c2a44f750",
      "0cbbac689fcc429198dcb037782b0528",
      "61b4b8adbb2741908a64d8f0f78de00c",
      "af74128984014196917b5fb9af02deb1",
      "904d077bb97f415097fca58570d92346",
      "df477f5e023d4b04861f2fac5fd6d799",
      "dba3a21f725f45219231ac9dcb773a61",
      "1e76fc08370a4ac8af825f45f494a932",
      "544b848d6d484016bb9fa22bc150ab9e",
      "b5f51c27d6f5428e8e1a1ddbe659e758",
      "8dda8f54336d4c35a1cb1b53a755e9ef",
      "a13726b59f0d432fb6009576d0a246d9",
      "168b20b3ee6942aa8754adb5831a5ee1",
      "ad43d66abf5e4c2e8ed6f7c845b9695b",
      "55d9b5d32698457fa78e1998fa2363d1",
      "48d2530ea4cd440f9264616a2af6d699",
      "56a86c16eb234c33816f79412a9be26e",
      "5aca586b60794a1bb09aac754f0a6705",
      "244cfbc8551d4baab6b33be4cc2582d1",
      "19adb62933ee489b83dd5edae3831e48",
      "1e100297708f43e4b9b9b17aa4c99bae",
      "648f473b479b4d0089a9fdb28cbb24b4",
      "7842b30aacfe46f98cb28afe87fcdd3a",
      "db4e9216ac454b21953d7f5a25ed037e",
      "02d3f7397fed47b988b0202eeb895715",
      "244899f5343640c1a03b755c531df877",
      "32eb1eaaaadf472cb8982ffd50bcce70",
      "60e5230e8f31411396760fa53da72345",
      "0b1536e1b7bd4e86826241937bba4c41",
      "39b0ec39f49f418e9716e7ebd07e6688",
      "3f38987b78d84fe383a2b1f66609a37b",
      "ac15d941cf764049bb9098adf8effd7c",
      "1b6623a281ad443da340e96833a35d97",
      "93609317e5a94a47a7bc3986e3f8da2a",
      "4a7f8535d06546ee98064417f9c36611",
      "a1f961e5896b43048b230e849e05decb",
      "f189dbe099eb4a58b546fdc3b46d4658",
      "d6e9133dee014d2982546d0d06cc4ab2",
      "0a68e4470800446fa1cd7738f5d2077b",
      "ddccba5b9cbe4f89ba1d99ff45f1ba75",
      "ae7174826fe744e1b57e731db1e83305",
      "72eed5e8ec4f4112890cab95f3725c4e",
      "a53dcd7dfede428db73371b6da9bafdd",
      "056fc5c6bca44e4698a69e2dbf09fe4d",
      "746ccdd5773f4997a8c8a3cc09ff3df5",
      "aebaec1dd88b4cd1a48cf969c40e1100",
      "af893c23dd674be38bf83dcdc5ec2844",
      "2cab0d7cf97f45efb5612881836b7a01",
      "37c61d292aa642b0a10a72b212934769",
      "88b0e5fae387441e9db8fbbf1cede218",
      "36b4333a055d44f890fb1f3d46ec5347",
      "21dc728bdff4475b828f2a3ecc6adfeb",
      "d998f18c8fe64c9b97dd4c25d49f7cb5",
      "958ad57f642a43ed9d71cd4bc96f1f87",
      "218e6ac5fda44340bba06c5868c87df8",
      "70ac8bad4c3346198972f3f14ae4d915",
      "17e7cdfeefec422190fdad2218deb648",
      "03a2712d63894eb19ca6c9faa8b4d837",
      "0259bced16924fd19b15ef0cc7d4b095",
      "f88092e6f42841ebb76a8404fd616084",
      "60eaf2874bf94acf9fab27df2b8df400",
      "fe46a627c96a4604b198f2e56dccce8f",
      "59d5c7df01084779a397ce2f951b33fa",
      "b0726c2951a44ef0aed9a274275bf829",
      "37fbe18e99b744cc9c030a7822289755",
      "3f32678f73ce4593bc0ed88b82f3728b",
      "6390974ce7224b909b70c52341606a8e",
      "0c4f3e0b5af64ae7a70994a3c1962a50",
      "24534516bc014554816f8850110f1d97",
      "f062fb314cc34965a0c33fa1e9deaf55",
      "e49c8916e9e14704a574ba4bcca9c5d7",
      "070fe8fa5aa645e09ab8c3e85a8e257e",
      "2ead5875cc7a4538aaeddc52849e723a",
      "83de7f46d25948baa0582385282c045c",
      "4de5ff7e6bc948ac9d24d370134bef6b",
      "c22646fb5cc34f4ab32072c758c93948",
      "6688690b18164fe893128d4bdfd5fc47",
      "4f6f284b8ddd4ac19f10b0fb3f25d507",
      "96d7d3743203419f8f73d564380e63dd",
      "568bbcd4dbcd4f66883916d3cd069473",
      "eab25e5eeb2f4a81973653cbb259b3dc",
      "211c9ea20785408fbf28bd9f345064ce",
      "95e27d1aa50948d78cf1a7a2839589ad",
      "41441a89a9274c79944c921add3f7759",
      "8ca9067f706b4e0c83a38a9aba8b16c4",
      "61332043a6604d1080aa5a0a323b6910",
      "65b2f194ec8944e8a6f89f0cbc37a251",
      "ac4ee4dacd7a4cac839563a14ecd9f84"
     ]
    },
    "collapsed": true,
    "id": "0L9mrE-jyrPH",
    "outputId": "0ad99283-8029-45de-849c-2de7395a1a81"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caa5b9137a0342888a84f7cca75a6534",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b68a05287f2b4b8e9484cfcb4d3b82ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1fefc6c887d479eace03f74c8e4db07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0/41 [00:00<?, ?files/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c79395f675b8465ab746a4e724f21731",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "20231101.en/train-00000-of-00041.parquet:   0%|          | 0.00/420M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "735ca48204df4db5a9e11aabbcedda4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "20231101.en/train-00001-of-00041.parquet:   0%|          | 0.00/351M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9210e373a12145aea3c0c3c25a8f31be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "20231101.en/train-00002-of-00041.parquet:   0%|          | 0.00/329M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07f0cbd40b294332b52e6245c94bf8ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "20231101.en/train-00003-of-00041.parquet:   0%|          | 0.00/331M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "856b9cdd36804e5685dec3a068b1c197",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "20231101.en/train-00004-of-00041.parquet:   0%|          | 0.00/307M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb94fc37ae734dfe8886d291a9540a67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "20231101.en/train-00005-of-00041.parquet:   0%|          | 0.00/244M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7d185b9961b47e1b2876aad7d637913",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "20231101.en/train-00006-of-00041.parquet:   0%|          | 0.00/266M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4549e39db2834769b79d780273aa89f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "20231101.en/train-00007-of-00041.parquet:   0%|          | 0.00/228M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06842af40312417ca890a20536ae16a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "20231101.en/train-00008-of-00041.parquet:   0%|          | 0.00/248M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "067c11a0f92e4b0f99db5942f998c2ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "20231101.en/train-00009-of-00041.parquet:   0%|          | 0.00/227M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23f2a01d8e904dc0b1df8e81857c7ac5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "20231101.en/train-00010-of-00041.parquet:   0%|          | 0.00/234M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd25eee0d27b4e19bbae193732206c6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "20231101.en/train-00011-of-00041.parquet:   0%|          | 0.00/232M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57e535056fb546f9ac5a61767da1e8b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "20231101.en/train-00012-of-00041.parquet:   0%|          | 0.00/239M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e622719e0eeb4b43a17c2b8e4b03dd8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "20231101.en/train-00013-of-00041.parquet:   0%|          | 0.00/241M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9b1392a5b3e487798b3e3f5f2825e6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "20231101.en/train-00014-of-00041.parquet:   0%|          | 0.00/223M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6225dfc0a3bb4d0ba53e213c4ae73904",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "20231101.en/train-00015-of-00041.parquet:   0%|          | 0.00/235M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c3a6e0262c9491589ce5aff7257c790",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "20231101.en/train-00016-of-00041.parquet:   0%|          | 0.00/503M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ab114565d294488b57e067e9776e37b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "20231101.en/train-00017-of-00041.parquet:   0%|          | 0.00/231M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a02f3e62bdde497182aac93efe0708e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "20231101.en/train-00018-of-00041.parquet:   0%|          | 0.00/231M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75d4436a90144b5bb89c8a7e315308dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "20231101.en/train-00019-of-00041.parquet:   0%|          | 0.00/195M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8051e4408b2149f8b472c9ba6767ee21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "20231101.en/train-00020-of-00041.parquet:   0%|          | 0.00/225M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d0e2c7c636a47abbd4a9d819098090d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "20231101.en/train-00021-of-00041.parquet:   0%|          | 0.00/216M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7edb761e5f1544cc968218e2a6b25cf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "20231101.en/train-00022-of-00041.parquet:   0%|          | 0.00/202M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff1a35c4abe94419b8cee294cdd557bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "20231101.en/train-00023-of-00041.parquet:   0%|          | 0.00/213M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9306ef94e3c4ce3b36a5ee885c30919",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "20231101.en/train-00024-of-00041.parquet:   0%|          | 0.00/221M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58d8119bb1ab49d0ac2e11aaec9e85b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "20231101.en/train-00025-of-00041.parquet:   0%|          | 0.00/221M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72110ce3dc1d45f886646433d925ca9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "20231101.en/train-00026-of-00041.parquet:   0%|          | 0.00/208M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5de23ac23ba04e21bd8174193601044d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "20231101.en/train-00027-of-00041.parquet:   0%|          | 0.00/214M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eff03a810bf94026a0d968bd6ce44eea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "20231101.en/train-00028-of-00041.parquet:   0%|          | 0.00/188M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ae4dae041f04e4e88d51ba28897f8a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "20231101.en/train-00029-of-00041.parquet:   0%|          | 0.00/218M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fe3f09f8f5e405a84962f4a390347cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "20231101.en/train-00030-of-00041.parquet:   0%|          | 0.00/204M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a862613e9e24e519cb8223688d9a72c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "20231101.en/train-00031-of-00041.parquet:   0%|          | 0.00/215M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b22b72d0ac449309602b316f10716a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "20231101.en/train-00032-of-00041.parquet:   0%|          | 0.00/214M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50c9d8945edd4e29b79bdb53934257ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "20231101.en/train-00033-of-00041.parquet:   0%|          | 0.00/203M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fc2a7cbd2a748faa6d17fa336b002bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "20231101.en/train-00034-of-00041.parquet:   0%|          | 0.00/219M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30c78e71895a453c8f262b4c2a44f750",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "20231101.en/train-00035-of-00041.parquet:   0%|          | 0.00/224M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a13726b59f0d432fb6009576d0a246d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "20231101.en/train-00036-of-00041.parquet:   0%|          | 0.00/610M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7842b30aacfe46f98cb28afe87fcdd3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "20231101.en/train-00037-of-00041.parquet:   0%|          | 0.00/674M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93609317e5a94a47a7bc3986e3f8da2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "20231101.en/train-00038-of-00041.parquet:   0%|          | 0.00/538M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "746ccdd5773f4997a8c8a3cc09ff3df5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "20231101.en/train-00039-of-00041.parquet:   0%|          | 0.00/465M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70ac8bad4c3346198972f3f14ae4d915",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "20231101.en/train-00040-of-00041.parquet:   0%|          | 0.00/422M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6390974ce7224b909b70c52341606a8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/6407814 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f6f284b8ddd4ac19f10b0fb3f25d507",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 4\n",
      "Validation dataset size: 4\n",
      "Test dataset size: 4\n",
      "Tokenizer saved to my_tokenizer.json\n",
      "Encoded IDs for 'I went to the bank': [45, 3668, 2032, 2015, 5057]\n",
      "Decoded text: I went to the bank\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "\n",
    "# Load the full 'train' split of the dataset as the initial dataset\n",
    "raw_train_dataset = load_dataset('wikimedia/wikipedia',\"20231101.en\", split=\"train\")\n",
    "\n",
    "# Split the raw_train_dataset into a new training set (80%) and a temporary set (20%)\n",
    "# The 'temp' set will then be split into validation and test.\n",
    "# Using a fixed seed for reproducibility.\n",
    "train_val_test_split = raw_train_dataset.train_test_split(test_size=0.2, seed=42)\n",
    "\n",
    "# The new 'train' split\n",
    "train_dataset = train_val_test_split['train'][:10000] # Corrected slicing\n",
    "\n",
    "# Split the 'test' part of train_val_test_split (which is 20% of original)\n",
    "# into validation (10% of original) and test (10% of original)\n",
    "val_test_dataset = train_val_test_split['test'].train_test_split(test_size=0.5, seed=42)\n",
    "\n",
    "validation_dataset = val_test_dataset['train'][:1000] # Corrected slicing\n",
    "test_dataset = val_test_dataset['test'][:1000] # Corrected slicing\n",
    "\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Validation dataset size: {len(validation_dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")\n",
    "\n",
    "from tokenizers import Tokenizer, models, trainers, pre_tokenizers\n",
    "\n",
    "# Creating a tokenizer with BPE model\n",
    "tokenizer = Tokenizer(models.BPE())\n",
    "\n",
    "# Pre-tokenizer (split on whitespace)\n",
    "tokenizer.pre_tokenizer = pre_tokenizers.Whitespace()\n",
    "\n",
    "# Trainer\n",
    "trainer = trainers.BpeTrainer(vocab_size=30000, min_frequency=2, special_tokens=[\"[UNK]\", \"[PAD]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"])\n",
    "\n",
    "\n",
    "corpus_file_path = \"wiki_train_corpus.txt\"\n",
    "with open(corpus_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    # Iterate directly over the 'text' list within the train_dataset dictionary\n",
    "    for text_entry in train_dataset['text']:\n",
    "        if text_entry is not None:\n",
    "            f.write(text_entry + \"\\n\")\n",
    "\n",
    "# Training on corpus files\n",
    "tokenizer.train(files=[corpus_file_path], trainer=trainer)\n",
    "\n",
    "# Saving the tokenizer for later use\n",
    "tokenizer_path = \"my_tokenizer.json\"\n",
    "tokenizer.save(tokenizer_path)\n",
    "print(f\"Tokenizer saved to {tokenizer_path}\")\n",
    "\n",
    "# Encoding text with the trained tokenizer for testing\n",
    "encoded = tokenizer.encode(\"I went to the bank\")\n",
    "print(f\"Encoded IDs for 'I went to the bank': {encoded.ids}\")\n",
    "print(f\"Decoded text: {tokenizer.decode(encoded.ids)}\")\n",
    "\n",
    "# Cleaning up the temporary corpus file\n",
    "os.remove(corpus_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XDqBpkKn8KqR",
    "outputId": "6f8df7fd-01d3-48c2-83d0-ba845662bc24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The 1992 Akron Zips football team represented Akron University in the 1992 NCAA Division I-A football season as members of the Mid-American Conference. They were led by seventhyear head coach Gerry Faust. The Zips played their home games at the Rubber Bowl in Akron, Ohio. They finished the season with a record of 731, 53 in MAC play to finish in a three-way tie for third place.\\n\\nSchedule\\n\\nReferences\\n\\nAkron\\nAkron Zips football seasons\\nAkron Zips football']\n"
     ]
    }
   ],
   "source": [
    "# making sure train_dataset is well set\n",
    "print(train_dataset['text'][:1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ebDsVYIC6E7R",
    "outputId": "d0c10e50-f1e0-404c-8207-e86f02d2e9f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_tensor_train shape: torch.Size([10000, 576])\n",
      "y_tensor_train shape: torch.Size([10000, 576])\n",
      "X_tensor_val shape: torch.Size([1000, 576])\n",
      "y_tensor_val shape: torch.Size([1000, 576])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from tokenizers import Tokenizer\n",
    "\n",
    "# Define a custom Dataset class (moved definition before usage)\n",
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "\n",
    "# Load the tokenizer trained in the previous cell\n",
    "tokenizer = Tokenizer.from_file(\"my_tokenizer.json\")\n",
    "\n",
    "# Define the sequence length, matching the model's seq_length (from cell 8AR8vdQqvSKs)\n",
    "SEQ_LENGTH = 576\n",
    "\n",
    "# Get the PAD token ID from the tokenizer\n",
    "pad_token_id = tokenizer.token_to_id(\"[PAD]\")\n",
    "if pad_token_id is None:\n",
    "    raise ValueError(\"PAD token ID not found. Ensure '[PAD]' is in tokenizer's special tokens.\")\n",
    "\n",
    "# Tokenize and prepare the data for X_tensor and y_tensor (TRAINING DATA)\n",
    "tokenized_sequences_train = []\n",
    "for text_entry in train_dataset['text']:\n",
    "    if text_entry is not None:\n",
    "        encoded = tokenizer.encode(text_entry)\n",
    "        ids = encoded.ids\n",
    "\n",
    "        # We need a sequence of length SEQ_LENGTH + 1 to create input and output sequences of SEQ_LENGTH\n",
    "        target_len = SEQ_LENGTH + 1\n",
    "\n",
    "        if len(ids) >= target_len:\n",
    "            processed_ids = ids[:target_len]\n",
    "        else: # Pad if shorter\n",
    "            processed_ids = ids + [pad_token_id] * (target_len - len(ids))\n",
    "        tokenized_sequences_train.append(processed_ids)\n",
    "\n",
    "# Convert the list of tokenized sequences to a PyTorch tensor\n",
    "if not tokenized_sequences_train:\n",
    "    raise ValueError(\"No tokenized sequences generated for training. train_dataset['text'] might be empty or contain only None values.\")\n",
    "\n",
    "idx_tensor_train = torch.tensor(tokenized_sequences_train, dtype=torch.long)\n",
    "\n",
    "# Apply the shifting logic to create X_tensor and y_tensor\n",
    "X_tensor_train = idx_tensor_train[:, :-1]\n",
    "y_tensor_train = idx_tensor_train[:, 1:]\n",
    "\n",
    "# Create the training dataset and DataLoader\n",
    "train_dataset_obj = MyDataset(X_tensor_train, y_tensor_train)\n",
    "train_loader = DataLoader(train_dataset_obj, batch_size=32, shuffle=True)\n",
    "\n",
    "print(f\"X_tensor_train shape: {X_tensor_train.shape}\")\n",
    "print(f\"y_tensor_train shape: {y_tensor_train.shape}\")\n",
    "\n",
    "# Tokenize and prepare the data for X_tensor and y_tensor (VALIDATION DATA)\n",
    "tokenized_sequences_val = []\n",
    "for text_entry in validation_dataset['text']:\n",
    "    if text_entry is not None:\n",
    "        encoded = tokenizer.encode(text_entry)\n",
    "        ids = encoded.ids\n",
    "\n",
    "        target_len = SEQ_LENGTH + 1\n",
    "\n",
    "        if len(ids) >= target_len:\n",
    "            processed_ids = ids[:target_len]\n",
    "        else:\n",
    "            processed_ids = ids + [pad_token_id] * (target_len - len(ids))\n",
    "        tokenized_sequences_val.append(processed_ids)\n",
    "\n",
    "if not tokenized_sequences_val:\n",
    "    raise ValueError(\"No tokenized sequences generated for validation. validation_dataset['text'] might be empty or contain only None values.\")\n",
    "\n",
    "idx_tensor_val = torch.tensor(tokenized_sequences_val, dtype=torch.long)\n",
    "\n",
    "X_tensor_val = idx_tensor_val[:, :-1]\n",
    "y_tensor_val = idx_tensor_val[:, 1:]\n",
    "\n",
    "# Create the validation dataset and DataLoader\n",
    "val_dataset_obj = MyDataset(X_tensor_val, y_tensor_val)\n",
    "validation_loader = DataLoader(val_dataset_obj, batch_size=32, shuffle=False) # No shuffle for validation\n",
    "\n",
    "print(f\"X_tensor_val shape: {X_tensor_val.shape}\")\n",
    "print(f\"y_tensor_val shape: {y_tensor_val.shape}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "84t2NcZhAcy9",
    "outputId": "03235a07-aa3c-4a8d-d09c-963e040f6d79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 30000\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer.from_file(\"my_tokenizer.json\")\n",
    "\n",
    "# checking vocab size making sure its same as we set it in our model\n",
    "vocab_size = tokenizer.get_vocab_size()\n",
    "print(\"Vocab size:\", vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_QnkhQQ0E5fd"
   },
   "source": [
    "# **Training From Scratch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "bQIrwrlxA1aZ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "# Training loop\n",
    "# epochs = 10\n",
    "prev_valloss = float('inf')\n",
    "i = 0\n",
    "overfitting = 0\n",
    "\n",
    "# We would train until it start overfitting with no max epoches\n",
    "while True:\n",
    "    model.train()  # Setting the model to training mode\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # print(''*1000)\n",
    "    print('new epoch')\n",
    "\n",
    "\n",
    "    for batch in train_loader:\n",
    "\n",
    "        X_batch, y_batch = batch\n",
    "        # Moving batches to the appropriate device\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        predictions,loss = model(X_batch,y_batch)\n",
    "        # loss = criterion(predictions, y_batch)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()  # Clearinf previous gradients\n",
    "        loss.backward()        # Computinf gradients\n",
    "        optimizer.step()       # Updating parameters\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        # print('new batch with loss:', loss.item())\n",
    "\n",
    "    # Calculate average training loss\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "\n",
    "    # Validation step\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation for evaluation\n",
    "        for batch in validation_loader:\n",
    "            X_batch, y_batch = batch\n",
    "            # Move batches to the appropriate device\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            predictions,loss = model(X_batch,y_batch)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # # Calculate accuracy\n",
    "            # predicted_labels = (predictions > 0.5).float()\n",
    "            # correct += (predicted_labels == y_batch).sum().item()\n",
    "            # total += y_batch.size(0)\n",
    "\n",
    "    avg_val_loss = val_loss / len(validation_loader)\n",
    "    # accuracy = correct / total\n",
    "\n",
    "\n",
    "    print(f\"Epoch {i+1}/{i}\")\n",
    "    print(f\"  Training Loss: {avg_train_loss:.4f}\")\n",
    "    print(f\"  Validation Loss: {avg_val_loss:.4f}\")\n",
    "    i += 1\n",
    "    if avg_val_loss >= prev_valloss:\n",
    "        overfitting += 1\n",
    "\n",
    "    else:\n",
    "        prev_valloss = avg_val_loss\n",
    "        overfitting = 0  # optional: reset if improved\n",
    "\n",
    "    if overfitting == 2:\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oUSMTRjYK5dE"
   },
   "outputs": [],
   "source": [
    "\n",
    "prompt = \"prompt\"\n",
    "\n",
    "# Get token IDs as plain Python ints\n",
    "encoded = tokenizer.encode(prompt)\n",
    "\n",
    "token_ids = [int(t) for t in encoded.ids]\n",
    "\n",
    "# print('token_ids',token_ids)\n",
    "\n",
    "# Convert to tensor, add batch dim, move to GPU\n",
    "token_tensor = torch.tensor(token_ids, dtype=torch.long).unsqueeze(0).to(device)\n",
    "\n",
    "# print('token_tensor',token_tensor)\n",
    "# print(\"token_tensor dtype:\", token_tensor.dtype)\n",
    "# print(\"token_tensor shape:\", token_tensor.shape)\n",
    "\n",
    "\n",
    "generated_sequence = model.generate(token_tensor, max_len=50, temperature=0.7, top_k=50)\n",
    "tokens = generated_sequence[0].tolist()\n",
    "text = tokenizer.decode(tokens)\n",
    "\n",
    "print(text)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0 (main, Nov  2 2023, 21:43:31) [Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "f1062708a37074d70712b695aadee582e0b0b9f95f45576b5521424137d05fec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
